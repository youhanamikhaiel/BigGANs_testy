{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "cifar_resnet_train_BCE.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "iqJNg5tQjJ5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "5221ce26-884b-42ef-8346-473e77011d4b"
      },
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "import resnetw"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-83b28c66b09d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mresnetw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'resnetw'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SIA0Scc5jJ5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ctime():\n",
        "    if torch.cuda.is_available(): torch.cuda.synchronize()\n",
        "    return(time.time())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UjMQJUyFjJ5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size = 125\n",
        "test_batch_size = 400\n",
        "verbose = 0\n",
        "epochs = 132\n",
        "pos_weight = 18  # 18 for CIFAR10 and 10 for CIFAR100\n",
        "alpha = 0.9\n",
        "threshold = 1.4\n",
        "weight_decay = 0.0001\n",
        "dataset = \"CIFAR10\"\n",
        "lr0 = 0.1\n",
        "width = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Ge6DD8IKjJ5q",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e30a857-526e-4bb8-81e0-1317837ceb96"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JT0lSu-3jJ5v",
        "colab_type": "code",
        "colab": {},
        "outputId": "0659fe9a-16bf-4015-afba-480754f91d59"
      },
      "source": [
        "# https://gist.github.com/weiaicunzai/e623931921efefd4c331622c344d8151\n",
        "# SVHN: mean=[0.4377, 0.4438, 0.4728], std=[0.1980, 0.2010, 0.1970]\n",
        "# MNIST: mean=[0.1307], std=[0.3081]\n",
        "# FashionMNIST: mean=[0.2860], std=[0.3530]\n",
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "def getSetsClasses(dataset, root='./data'):\n",
        "    if (dataset == 'CIFAR10'):\n",
        "        normalize = transforms.Normalize(\n",
        "            mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n",
        "        transform_train = transforms.Compose(\n",
        "            [transforms.RandomHorizontalFlip(),\n",
        "             transforms.RandomCrop(32, 4),\n",
        "             transforms.ToTensor(), normalize])\n",
        "        transform_test = transforms.Compose(\n",
        "            [transforms.ToTensor(), normalize])\n",
        "        trainset = torchvision.datasets.CIFAR10(\n",
        "            root=root, train=True, download=True, transform=transform_train)\n",
        "        testset = torchvision.datasets.CIFAR10(\n",
        "            root=root, train=False, download=True, transform=transform_test)\n",
        "        with open(root+'/cifar-10-batches-py/batches.meta', 'rb') as f:\n",
        "            classes = pickle.load(f)[\"label_names\"]\n",
        "        return trainset, testset, classes\n",
        "    if (dataset == 'CIFAR100'):\n",
        "        normalize = transforms.Normalize(\n",
        "            mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n",
        "        transform_train = transforms.Compose(\n",
        "            [transforms.RandomHorizontalFlip(),\n",
        "             transforms.RandomCrop(32, 4),\n",
        "             transforms.ToTensor(), normalize])\n",
        "        transform_test = transforms.Compose(\n",
        "            [transforms.ToTensor(), normalize])\n",
        "        trainset = torchvision.datasets.CIFAR100(\n",
        "            root=root, train=True, download=True, transform=transform_train)\n",
        "        testset = torchvision.datasets.CIFAR100(\n",
        "            root=root, train=False, download=True, transform=transform_test)\n",
        "        with open(root+'/cifar-100-python/meta', 'rb') as f:\n",
        "            classes = pickle.load(f)[\"fine_label_names\"]\n",
        "        return trainset, testset, classes\n",
        "    return None\n",
        "\n",
        "trainset, testset, classes = getSetsClasses(dataset)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=train_batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=test_batch_size, shuffle=False, num_workers=8, pin_memory=True)\n",
        "num_classes = len(classes)\n",
        "print(num_classes, \"classes\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "10 classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "E-0ouhcdjJ5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getScoresLabels(net, loader, device):\n",
        "    # Not memory efficient\n",
        "    lscores = []\n",
        "    llabels = []\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = net(inputs)\n",
        "            lscores.append(outputs)\n",
        "            llabels.append(F.one_hot(labels, torch.tensor(outputs.size())[1].item()))\n",
        "    return torch.cat(lscores), torch.cat(llabels)\n",
        "\n",
        "def getRates(scores, labels, threshold = 0):\n",
        "    num_classes = torch.tensor(scores.size())[1].item()\n",
        "    rates = torch.zeros(4, num_classes, dtype=torch.int).to(device)\n",
        "    predicted = (scores > threshold).int()\n",
        "    # true negatives, false negative, false positive, true positive\n",
        "    rates[0] = torch.sum(((predicted == 0) & (labels == 0)).int(), dim=0)\n",
        "    rates[1] = torch.sum(((predicted == 0) & (labels == 1)).int(), dim=0)\n",
        "    rates[2] = torch.sum(((predicted == 1) & (labels == 0)).int(), dim=0)\n",
        "    rates[3] = torch.sum(((predicted == 1) & (labels == 1)).int(), dim=0)\n",
        "    return rates\n",
        "\n",
        "def accuracy(scores, labels):\n",
        "    num_classes = torch.tensor(scores.size())[1].item()\n",
        "    class_correct = list(0. for i in range(num_classes))\n",
        "    class_total = list(0. for i in range(num_classes))\n",
        "    predicted = torch.argmax(scores, 1)\n",
        "    truelabel = torch.argmax(labels, 1)\n",
        "    c = (predicted == truelabel).squeeze()\n",
        "    for i in range(list(scores.shape)[0]):\n",
        "        label = truelabel[i]\n",
        "        class_correct[label] += c[i].item()\n",
        "        class_total[label] += 1\n",
        "    return class_correct, class_total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "NY9weAo4jJ53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self, w = 32, h = 32, i = 3, n = [6, 16, 120, 84], o = 10):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(i, n[0], 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(n[0], n[1], 5)\n",
        "        self.fc1 = nn.Linear(n[1] * (w//4-3) * (h//4-3), n[2])\n",
        "        self.fc2 = nn.Linear(n[2], n[3])\n",
        "        self.fc3 = nn.Linear(n[3], o)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, torch.prod(torch.tensor(list(x.size()[1:]))).item())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "gd3sLlOejJ57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(net, loader, device, set = 'Test'):\n",
        "    t0 = ctime()\n",
        "    scores, labels = getScoresLabels(net, loader, device)\n",
        "    # class_correct, class_total = accuracy(scores, labels)\n",
        "    class_correct, class_total = accuracy(scores, labels)\n",
        "    print('%s time: %3.2fs' % (set, ctime()-t0), end = \"  \")\n",
        "    print('Accuracy: %2.2f %%' % (100 * sum(class_correct) / sum(class_total)), end = \"  \")\n",
        "    labels = labels.to(\"cpu\").numpy()\n",
        "    scores = scores.to(\"cpu\").numpy()\n",
        "    map = torch.tensor(average_precision_score(labels, scores, average=None)).float().mean().item()\n",
        "    print('%s MAP: %2.2f %%' % (set, 100 * map))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fdBh_hZFjJ5-",
        "colab_type": "code",
        "colab": {},
        "outputId": "c1add905-d572-4bc5-e3a6-b5c008bdac9e"
      },
      "source": [
        "t0 = ctime()\n",
        "#net = LeNet(n=[32, 32, 240, 120], o=num_classes).to(device)\n",
        "net = resnetw.ResNet(resnetw.BasicBlock, [3, 3, 3], num_classes=num_classes, width=width).to(device)\n",
        "print('Init time:   %3.2fs' % (ctime()-t0), end = \"  \")\n",
        "evaluate(net, testloader, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init time:   0.08s  Test time: 2.35s  Accuracy: 10.00 %  Test MAP: 11.36 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WdqC31T_jJ6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterionMC = nn.CrossEntropyLoss()\n",
        "criterionML = nn.BCEWithLogitsLoss(pos_weight=pos_weight*torch.ones([num_classes]).to(device))\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr0, momentum=0.9, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[epochs//2,(3*epochs)//4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvOSXkLnjJ6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch, net, trainloader, device, optimizer, scheduler, criterionMC, criterionML, alpha):\n",
        "    print('Epoch: %3d' % epoch, end = \"  \")\n",
        "    running_loss = 0.0\n",
        "    t0 = ctime()\n",
        "    net.train()\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        if (alpha <= 0): loss = criterionMC(outputs, labels)\n",
        "        elif (alpha >= 1): loss = criterionML(outputs, F.one_hot(labels,num_classes).type_as(outputs))\n",
        "        else: loss = (1-alpha)*criterionMC(outputs, labels) + \\\n",
        "            alpha*criterionML(outputs, F.one_hot(labels,num_classes).type_as(outputs))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print('Train time: %3.2fs' % (ctime()-t0), end = \"  \")\n",
        "    print('Train loss: %5.4f' % (running_loss*train_batch_size/len(trainset)), end = \"  \")    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "DLFLJWmEjJ6G",
        "colab_type": "code",
        "colab": {},
        "outputId": "9f8a2814-8533-4b99-d6a3-a5ee8169eb26"
      },
      "source": [
        "t1 = ctime()\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "    train(epoch, net, trainloader, device, optimizer, scheduler, criterionMC, criterionML, alpha)\n",
        "    evaluate(net, testloader, device)\n",
        "    scheduler.step()\n",
        "tt = ctime()-t1\n",
        "print('Finished Training, total time %4.2fs' % (tt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   0  Train time: 24.56s  Train loss: 1.3669  Test time: 2.01s  Accuracy: 40.46 %  Test MAP: 44.08 %\n",
            "Epoch:   1  Train time: 24.74s  Train loss: 0.9291  Test time: 2.03s  Accuracy: 54.14 %  Test MAP: 63.22 %\n",
            "Epoch:   2  Train time: 24.87s  Train loss: 0.7494  Test time: 2.04s  Accuracy: 64.56 %  Test MAP: 74.51 %\n",
            "Epoch:   3  Train time: 24.90s  Train loss: 0.6207  Test time: 2.03s  Accuracy: 74.92 %  Test MAP: 82.24 %\n",
            "Epoch:   4  Train time: 24.96s  Train loss: 0.5358  Test time: 2.03s  Accuracy: 73.40 %  Test MAP: 82.86 %\n",
            "Epoch:   5  Train time: 25.02s  Train loss: 0.4663  Test time: 2.04s  Accuracy: 77.20 %  Test MAP: 86.21 %\n",
            "Epoch:   6  Train time: 25.00s  Train loss: 0.4162  Test time: 2.04s  Accuracy: 77.21 %  Test MAP: 88.32 %\n",
            "Epoch:   7  Train time: 25.01s  Train loss: 0.3811  Test time: 2.03s  Accuracy: 67.86 %  Test MAP: 85.49 %\n",
            "Epoch:   8  Train time: 25.00s  Train loss: 0.3429  Test time: 2.03s  Accuracy: 83.94 %  Test MAP: 91.91 %\n",
            "Epoch:   9  Train time: 24.99s  Train loss: 0.3258  Test time: 2.03s  Accuracy: 81.63 %  Test MAP: 91.29 %\n",
            "Epoch:  10  Train time: 25.05s  Train loss: 0.2992  Test time: 2.02s  Accuracy: 84.77 %  Test MAP: 92.68 %\n",
            "Epoch:  11  Train time: 25.03s  Train loss: 0.2820  Test time: 2.02s  Accuracy: 83.69 %  Test MAP: 92.80 %\n",
            "Epoch:  12  Train time: 25.01s  Train loss: 0.2636  Test time: 2.02s  Accuracy: 85.88 %  Test MAP: 93.80 %\n",
            "Epoch:  13  Train time: 25.01s  Train loss: 0.2499  Test time: 2.05s  Accuracy: 84.87 %  Test MAP: 93.26 %\n",
            "Epoch:  14  Train time: 25.03s  Train loss: 0.2373  Test time: 2.03s  Accuracy: 84.03 %  Test MAP: 93.40 %\n",
            "Epoch:  15  Train time: 25.01s  Train loss: 0.2269  Test time: 2.02s  Accuracy: 86.50 %  Test MAP: 94.02 %\n",
            "Epoch:  16  Train time: 25.01s  Train loss: 0.2220  Test time: 2.05s  Accuracy: 87.42 %  Test MAP: 94.44 %\n",
            "Epoch:  17  Train time: 25.01s  Train loss: 0.2066  Test time: 2.04s  Accuracy: 87.23 %  Test MAP: 94.74 %\n",
            "Epoch:  18  Train time: 25.02s  Train loss: 0.1994  Test time: 2.04s  Accuracy: 86.41 %  Test MAP: 94.70 %\n",
            "Epoch:  19  Train time: 25.00s  Train loss: 0.1942  Test time: 2.03s  Accuracy: 88.83 %  Test MAP: 95.30 %\n",
            "Epoch:  20  Train time: 25.01s  Train loss: 0.1818  Test time: 2.03s  Accuracy: 87.32 %  Test MAP: 95.15 %\n",
            "Epoch:  21  Train time: 25.01s  Train loss: 0.1790  Test time: 2.03s  Accuracy: 86.01 %  Test MAP: 94.94 %\n",
            "Epoch:  22  Train time: 24.98s  Train loss: 0.1765  Test time: 2.02s  Accuracy: 87.80 %  Test MAP: 95.39 %\n",
            "Epoch:  23  Train time: 25.03s  Train loss: 0.1696  Test time: 2.03s  Accuracy: 89.07 %  Test MAP: 95.58 %\n",
            "Epoch:  24  Train time: 25.01s  Train loss: 0.1703  Test time: 2.03s  Accuracy: 88.10 %  Test MAP: 95.41 %\n",
            "Epoch:  25  Train time: 25.00s  Train loss: 0.1620  Test time: 2.05s  Accuracy: 88.22 %  Test MAP: 95.28 %\n",
            "Epoch:  26  Train time: 25.00s  Train loss: 0.1611  Test time: 2.03s  Accuracy: 88.49 %  Test MAP: 95.32 %\n",
            "Epoch:  27  Train time: 25.03s  Train loss: 0.1520  Test time: 2.04s  Accuracy: 88.39 %  Test MAP: 95.54 %\n",
            "Epoch:  28  Train time: 25.01s  Train loss: 0.1525  Test time: 2.05s  Accuracy: 87.59 %  Test MAP: 95.51 %\n",
            "Epoch:  29  Train time: 25.01s  Train loss: 0.1470  Test time: 2.04s  Accuracy: 86.56 %  Test MAP: 94.90 %\n",
            "Epoch:  30  Train time: 25.01s  Train loss: 0.1511  Test time: 2.02s  Accuracy: 89.40 %  Test MAP: 95.83 %\n",
            "Epoch:  31  Train time: 25.04s  Train loss: 0.1426  Test time: 2.03s  Accuracy: 87.03 %  Test MAP: 95.01 %\n",
            "Epoch:  32  Train time: 25.02s  Train loss: 0.1436  Test time: 2.04s  Accuracy: 87.08 %  Test MAP: 95.36 %\n",
            "Epoch:  33  Train time: 25.00s  Train loss: 0.1367  Test time: 2.04s  Accuracy: 89.02 %  Test MAP: 95.97 %\n",
            "Epoch:  34  Train time: 25.00s  Train loss: 0.1306  Test time: 2.03s  Accuracy: 87.05 %  Test MAP: 95.51 %\n",
            "Epoch:  35  Train time: 25.00s  Train loss: 0.1333  Test time: 2.02s  Accuracy: 89.27 %  Test MAP: 95.84 %\n",
            "Epoch:  36  Train time: 25.01s  Train loss: 0.1373  Test time: 2.04s  Accuracy: 87.98 %  Test MAP: 95.61 %\n",
            "Epoch:  37  Train time: 25.00s  Train loss: 0.1264  Test time: 2.04s  Accuracy: 87.54 %  Test MAP: 95.35 %\n",
            "Epoch:  38  Train time: 25.00s  Train loss: 0.1301  Test time: 2.03s  Accuracy: 86.66 %  Test MAP: 95.37 %\n",
            "Epoch:  39  Train time: 24.99s  Train loss: 0.1244  Test time: 2.03s  Accuracy: 87.66 %  Test MAP: 95.38 %\n",
            "Epoch:  40  Train time: 25.00s  Train loss: 0.1288  Test time: 2.03s  Accuracy: 87.58 %  Test MAP: 95.34 %\n",
            "Epoch:  41  Train time: 24.99s  Train loss: 0.1211  Test time: 2.02s  Accuracy: 88.97 %  Test MAP: 96.30 %\n",
            "Epoch:  42  Train time: 24.98s  Train loss: 0.1197  Test time: 2.04s  Accuracy: 90.00 %  Test MAP: 96.23 %\n",
            "Epoch:  43  Train time: 25.04s  Train loss: 0.1146  Test time: 2.05s  Accuracy: 89.41 %  Test MAP: 96.01 %\n",
            "Epoch:  44  Train time: 25.00s  Train loss: 0.1269  Test time: 2.05s  Accuracy: 89.38 %  Test MAP: 96.36 %\n",
            "Epoch:  45  Train time: 24.98s  Train loss: 0.1174  Test time: 2.04s  Accuracy: 90.51 %  Test MAP: 96.72 %\n",
            "Epoch:  46  Train time: 24.99s  Train loss: 0.1150  Test time: 2.06s  Accuracy: 89.66 %  Test MAP: 96.01 %\n",
            "Epoch:  47  Train time: 25.01s  Train loss: 0.1123  Test time: 2.03s  Accuracy: 88.71 %  Test MAP: 95.60 %\n",
            "Epoch:  48  Train time: 25.02s  Train loss: 0.1197  Test time: 2.03s  Accuracy: 89.81 %  Test MAP: 96.32 %\n",
            "Epoch:  49  Train time: 24.99s  Train loss: 0.1133  Test time: 2.11s  Accuracy: 89.30 %  Test MAP: 96.35 %\n",
            "Epoch:  50  Train time: 25.02s  Train loss: 0.1132  Test time: 2.04s  Accuracy: 89.39 %  Test MAP: 96.59 %\n",
            "Epoch:  51  Train time: 24.99s  Train loss: 0.1093  Test time: 2.04s  Accuracy: 89.93 %  Test MAP: 96.52 %\n",
            "Epoch:  52  Train time: 24.99s  Train loss: 0.1068  Test time: 2.04s  Accuracy: 84.42 %  Test MAP: 94.30 %\n",
            "Epoch:  53  Train time: 24.98s  Train loss: 0.1081  Test time: 2.04s  Accuracy: 90.02 %  Test MAP: 96.33 %\n",
            "Epoch:  54  Train time: 24.99s  Train loss: 0.1094  Test time: 2.03s  Accuracy: 90.11 %  Test MAP: 96.73 %\n",
            "Epoch:  55  Train time: 24.97s  Train loss: 0.1071  Test time: 2.03s  Accuracy: 88.91 %  Test MAP: 96.17 %\n",
            "Epoch:  56  Train time: 24.97s  Train loss: 0.1075  Test time: 2.05s  Accuracy: 88.49 %  Test MAP: 96.19 %\n",
            "Epoch:  57  Train time: 25.00s  Train loss: 0.1039  Test time: 2.04s  Accuracy: 90.20 %  Test MAP: 96.58 %\n",
            "Epoch:  58  Train time: 25.00s  Train loss: 0.1033  Test time: 2.03s  Accuracy: 89.62 %  Test MAP: 96.48 %\n",
            "Epoch:  59  Train time: 25.01s  Train loss: 0.1078  Test time: 2.04s  Accuracy: 88.99 %  Test MAP: 96.53 %\n",
            "Epoch:  60  Train time: 24.98s  Train loss: 0.1060  Test time: 2.04s  Accuracy: 90.06 %  Test MAP: 96.62 %\n",
            "Epoch:  61  Train time: 24.98s  Train loss: 0.1012  Test time: 2.03s  Accuracy: 89.71 %  Test MAP: 96.32 %\n",
            "Epoch:  62  Train time: 24.98s  Train loss: 0.1021  Test time: 2.03s  Accuracy: 84.64 %  Test MAP: 95.72 %\n",
            "Epoch:  63  Train time: 25.03s  Train loss: 0.1003  Test time: 2.04s  Accuracy: 89.17 %  Test MAP: 96.22 %\n",
            "Epoch:  64  Train time: 25.01s  Train loss: 0.1024  Test time: 2.03s  Accuracy: 88.94 %  Test MAP: 96.00 %\n",
            "Epoch:  65  Train time: 25.00s  Train loss: 0.1012  Test time: 2.03s  Accuracy: 89.87 %  Test MAP: 96.46 %\n",
            "Epoch:  66  Train time: 25.00s  Train loss: 0.0458  Test time: 2.06s  Accuracy: 93.62 %  Test MAP: 98.17 %\n",
            "Epoch:  67  Train time: 25.03s  Train loss: 0.0268  Test time: 2.03s  Accuracy: 93.84 %  Test MAP: 98.24 %\n",
            "Epoch:  68  Train time: 24.97s  Train loss: 0.0220  Test time: 2.04s  Accuracy: 93.92 %  Test MAP: 98.28 %\n",
            "Epoch:  69  Train time: 25.00s  Train loss: 0.0194  Test time: 2.07s  Accuracy: 93.88 %  Test MAP: 98.33 %\n",
            "Epoch:  70  Train time: 24.98s  Train loss: 0.0153  Test time: 2.03s  Accuracy: 94.12 %  Test MAP: 98.33 %\n",
            "Epoch:  71  Train time: 24.98s  Train loss: 0.0147  Test time: 2.05s  Accuracy: 94.15 %  Test MAP: 98.33 %\n",
            "Epoch:  72  Train time: 24.97s  Train loss: 0.0129  Test time: 2.02s  Accuracy: 94.18 %  Test MAP: 98.34 %\n",
            "Epoch:  73  Train time: 24.97s  Train loss: 0.0111  Test time: 2.04s  Accuracy: 94.25 %  Test MAP: 98.38 %\n",
            "Epoch:  74  Train time: 24.98s  Train loss: 0.0109  Test time: 2.04s  Accuracy: 94.04 %  Test MAP: 98.34 %\n",
            "Epoch:  75  Train time: 25.02s  Train loss: 0.0109  Test time: 2.04s  Accuracy: 94.23 %  Test MAP: 98.36 %\n",
            "Epoch:  76  Train time: 25.01s  Train loss: 0.0092  Test time: 2.04s  Accuracy: 94.30 %  Test MAP: 98.37 %\n",
            "Epoch:  77  Train time: 25.05s  Train loss: 0.0091  Test time: 2.04s  Accuracy: 94.34 %  Test MAP: 98.34 %\n",
            "Epoch:  78  Train time: 24.99s  Train loss: 0.0079  Test time: 2.03s  Accuracy: 94.35 %  Test MAP: 98.36 %\n",
            "Epoch:  79  Train time: 25.00s  Train loss: 0.0075  Test time: 2.03s  Accuracy: 94.40 %  Test MAP: 98.33 %\n",
            "Epoch:  80  Train time: 25.00s  Train loss: 0.0072  Test time: 2.02s  Accuracy: 94.37 %  Test MAP: 98.30 %\n",
            "Epoch:  81  Train time: 25.05s  Train loss: 0.0069  Test time: 2.04s  Accuracy: 94.48 %  Test MAP: 98.34 %\n",
            "Epoch:  82  Train time: 25.01s  Train loss: 0.0068  Test time: 2.03s  Accuracy: 94.32 %  Test MAP: 98.32 %\n",
            "Epoch:  83  Train time: 25.00s  Train loss: 0.0060  Test time: 2.03s  Accuracy: 94.41 %  Test MAP: 98.34 %\n",
            "Epoch:  84  Train time: 25.03s  Train loss: 0.0061  Test time: 2.03s  Accuracy: 94.50 %  Test MAP: 98.34 %\n",
            "Epoch:  85  Train time: 25.01s  Train loss: 0.0056  Test time: 2.04s  Accuracy: 94.37 %  Test MAP: 98.33 %\n",
            "Epoch:  86  Train time: 25.01s  Train loss: 0.0052  Test time: 2.03s  Accuracy: 94.43 %  Test MAP: 98.31 %\n",
            "Epoch:  87  Train time: 24.99s  Train loss: 0.0052  Test time: 2.03s  Accuracy: 94.40 %  Test MAP: 98.31 %\n",
            "Epoch:  88  Train time: 24.99s  Train loss: 0.0049  Test time: 2.04s  Accuracy: 94.41 %  Test MAP: 98.29 %\n",
            "Epoch:  89  Train time: 25.01s  Train loss: 0.0044  Test time: 2.04s  Accuracy: 94.50 %  Test MAP: 98.29 %\n",
            "Epoch:  90  Train time: 25.01s  Train loss: 0.0044  Test time: 2.03s  Accuracy: 94.53 %  Test MAP: 98.33 %\n",
            "Epoch:  91  Train time: 25.00s  Train loss: 0.0044  Test time: 2.03s  Accuracy: 94.39 %  Test MAP: 98.32 %\n",
            "Epoch:  92  Train time: 24.98s  Train loss: 0.0044  Test time: 2.03s  Accuracy: 94.39 %  Test MAP: 98.27 %\n",
            "Epoch:  93  Train time: 24.99s  Train loss: 0.0040  Test time: 2.03s  Accuracy: 94.60 %  Test MAP: 98.32 %\n",
            "Epoch:  94  Train time: 25.00s  Train loss: 0.0039  Test time: 2.03s  Accuracy: 94.58 %  Test MAP: 98.31 %\n",
            "Epoch:  95  Train time: 25.00s  Train loss: 0.0041  Test time: 2.02s  Accuracy: 94.64 %  Test MAP: 98.31 %\n",
            "Epoch:  96  Train time: 24.99s  Train loss: 0.0037  Test time: 2.05s  Accuracy: 94.57 %  Test MAP: 98.25 %\n",
            "Epoch:  97  Train time: 24.99s  Train loss: 0.0039  Test time: 2.04s  Accuracy: 94.45 %  Test MAP: 98.25 %\n",
            "Epoch:  98  Train time: 24.99s  Train loss: 0.0041  Test time: 2.04s  Accuracy: 94.45 %  Test MAP: 98.26 %\n",
            "Epoch:  99  Train time: 25.03s  Train loss: 0.0035  Test time: 2.05s  Accuracy: 94.46 %  Test MAP: 98.27 %\n",
            "Epoch: 100  Train time: 24.97s  Train loss: 0.0035  Test time: 2.04s  Accuracy: 94.45 %  Test MAP: 98.26 %\n",
            "Epoch: 101  Train time: 25.01s  Train loss: 0.0035  Test time: 2.03s  Accuracy: 94.46 %  Test MAP: 98.29 %\n",
            "Epoch: 102  Train time: 25.02s  Train loss: 0.0031  Test time: 2.04s  Accuracy: 94.55 %  Test MAP: 98.27 %\n",
            "Epoch: 103  Train time: 24.98s  Train loss: 0.0033  Test time: 2.03s  Accuracy: 94.53 %  Test MAP: 98.26 %\n",
            "Epoch: 104  Train time: 24.97s  Train loss: 0.0032  Test time: 2.03s  Accuracy: 94.51 %  Test MAP: 98.27 %\n",
            "Epoch: 105  Train time: 24.99s  Train loss: 0.0032  Test time: 2.03s  Accuracy: 94.43 %  Test MAP: 98.27 %\n",
            "Epoch: 106  Train time: 24.98s  Train loss: 0.0033  Test time: 2.05s  Accuracy: 94.50 %  Test MAP: 98.28 %\n",
            "Epoch: 107  Train time: 25.02s  Train loss: 0.0033  Test time: 2.03s  Accuracy: 94.55 %  Test MAP: 98.28 %\n",
            "Epoch: 108  Train time: 24.98s  Train loss: 0.0033  Test time: 2.03s  Accuracy: 94.51 %  Test MAP: 98.29 %\n",
            "Epoch: 109  Train time: 24.99s  Train loss: 0.0031  Test time: 2.04s  Accuracy: 94.51 %  Test MAP: 98.27 %\n",
            "Epoch: 110  Train time: 24.98s  Train loss: 0.0031  Test time: 2.04s  Accuracy: 94.46 %  Test MAP: 98.29 %\n",
            "Epoch: 111  Train time: 25.01s  Train loss: 0.0031  Test time: 2.05s  Accuracy: 94.48 %  Test MAP: 98.30 %\n",
            "Epoch: 112  Train time: 24.99s  Train loss: 0.0031  Test time: 2.04s  Accuracy: 94.54 %  Test MAP: 98.29 %\n",
            "Epoch: 113  Train time: 24.99s  Train loss: 0.0030  Test time: 2.04s  Accuracy: 94.59 %  Test MAP: 98.30 %\n",
            "Epoch: 114  Train time: 25.01s  Train loss: 0.0030  Test time: 2.02s  Accuracy: 94.45 %  Test MAP: 98.28 %\n",
            "Epoch: 115  Train time: 25.01s  Train loss: 0.0031  Test time: 2.04s  Accuracy: 94.57 %  Test MAP: 98.28 %\n",
            "Epoch: 116  Train time: 24.99s  Train loss: 0.0031  Test time: 2.04s  Accuracy: 94.48 %  Test MAP: 98.29 %\n",
            "Epoch: 117  Train time: 25.04s  Train loss: 0.0029  Test time: 2.03s  Accuracy: 94.53 %  Test MAP: 98.29 %\n",
            "Epoch: 118  Train time: 24.99s  Train loss: 0.0029  Test time: 2.03s  Accuracy: 94.53 %  Test MAP: 98.29 %\n",
            "Epoch: 119  Train time: 25.04s  Train loss: 0.0030  Test time: 2.05s  Accuracy: 94.60 %  Test MAP: 98.29 %\n",
            "Epoch: 120  Train time: 24.99s  Train loss: 0.0029  Test time: 2.03s  Accuracy: 94.63 %  Test MAP: 98.31 %\n",
            "Epoch: 121  Train time: 24.98s  Train loss: 0.0027  Test time: 2.04s  Accuracy: 94.49 %  Test MAP: 98.31 %\n",
            "Epoch: 122  Train time: 24.98s  Train loss: 0.0030  Test time: 2.04s  Accuracy: 94.54 %  Test MAP: 98.32 %\n",
            "Epoch: 123  Train time: 24.98s  Train loss: 0.0028  Test time: 2.02s  Accuracy: 94.49 %  Test MAP: 98.31 %\n",
            "Epoch: 124  Train time: 24.97s  Train loss: 0.0031  Test time: 2.05s  Accuracy: 94.57 %  Test MAP: 98.30 %\n",
            "Epoch: 125  Train time: 25.03s  Train loss: 0.0028  Test time: 2.04s  Accuracy: 94.60 %  Test MAP: 98.32 %\n",
            "Epoch: 126  Train time: 24.99s  Train loss: 0.0029  Test time: 2.06s  Accuracy: 94.63 %  Test MAP: 98.29 %\n",
            "Epoch: 127  Train time: 25.01s  Train loss: 0.0028  Test time: 2.03s  Accuracy: 94.57 %  Test MAP: 98.32 %\n",
            "Epoch: 128  Train time: 25.02s  Train loss: 0.0027  Test time: 2.04s  Accuracy: 94.58 %  Test MAP: 98.29 %\n",
            "Epoch: 129  Train time: 24.99s  Train loss: 0.0028  Test time: 2.04s  Accuracy: 94.55 %  Test MAP: 98.29 %\n",
            "Epoch: 130  Train time: 25.00s  Train loss: 0.0028  Test time: 2.03s  Accuracy: 94.60 %  Test MAP: 98.30 %\n",
            "Epoch: 131  Train time: 25.04s  Train loss: 0.0027  Test time: 2.03s  Accuracy: 94.56 %  Test MAP: 98.29 %\n",
            "Finished Training, total time 3570.69s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "y7rWKIhojJ6K",
        "colab_type": "code",
        "colab": {},
        "outputId": "0020b1ce-342b-45fc-dbe5-c62d37448592"
      },
      "source": [
        "t0 = ctime()\n",
        "scores, labels = getScoresLabels(net, testloader, device)\n",
        "class_correct, class_total = accuracy(scores, labels)\n",
        "print('Test time: %3.2fs' % (ctime()-t0))\n",
        "\n",
        "print('Overall accuracy  : %2.2f %%' % (\n",
        "    100 * sum(class_correct) / sum(class_total)))\n",
        "\n",
        "for i in range(num_classes):\n",
        "    print('Accuracy of %5s : %2.2f %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test time: 2.05s\n",
            "Overall accuracy  : 94.56 %\n",
            "Accuracy of airplane : 95.60 %\n",
            "Accuracy of automobile : 97.60 %\n",
            "Accuracy of  bird : 91.90 %\n",
            "Accuracy of   cat : 89.80 %\n",
            "Accuracy of  deer : 96.70 %\n",
            "Accuracy of   dog : 89.70 %\n",
            "Accuracy of  frog : 96.50 %\n",
            "Accuracy of horse : 95.70 %\n",
            "Accuracy of  ship : 96.00 %\n",
            "Accuracy of truck : 96.10 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "0VJ4mAEtjJ6N",
        "colab_type": "code",
        "colab": {},
        "outputId": "0e73f9dc-9755-44cb-b7e4-afcfebe96709"
      },
      "source": [
        "scores, labels = getScoresLabels(net, testloader, device)\n",
        "rates = getRates(scores, labels, threshold = threshold)\n",
        "print(\"true negatives, false negative, false positive, true positive\")\n",
        "print(rates)\n",
        "cor = rates[3].float()\n",
        "pre = cor/(rates[3]+rates[2])\n",
        "rec = cor/(rates[3]+rates[1])\n",
        "print(pre)\n",
        "print(pre.mean().item())\n",
        "print(rec)\n",
        "print(rec.mean().item())\n",
        "labels = labels.to(\"cpu\").numpy()\n",
        "scores = scores.to(\"cpu\").numpy()\n",
        "ap = torch.tensor(average_precision_score(labels, scores, average=None)).float()\n",
        "print(ap)\n",
        "map = ap.mean().item()\n",
        "print(map)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "true negatives, false negative, false positive, true positive\n",
            "tensor([[8937, 8967, 8949, 8863, 8936, 8928, 8971, 8981, 8966, 8962],\n",
            "        [  44,   21,   92,  101,   31,  103,   37,   41,   40,   38],\n",
            "        [  63,   33,   51,  137,   64,   72,   29,   19,   34,   38],\n",
            "        [ 956,  979,  908,  899,  969,  897,  963,  959,  960,  962]],\n",
            "       device='cuda:0', dtype=torch.int32)\n",
            "tensor([0.9382, 0.9674, 0.9468, 0.8678, 0.9380, 0.9257, 0.9708, 0.9806, 0.9658,\n",
            "        0.9620], device='cuda:0')\n",
            "0.946302056312561\n",
            "tensor([0.9560, 0.9790, 0.9080, 0.8990, 0.9690, 0.8970, 0.9630, 0.9590, 0.9600,\n",
            "        0.9620], device='cuda:0')\n",
            "0.9451999664306641\n",
            "tensor([0.9864, 0.9931, 0.9785, 0.9514, 0.9880, 0.9604, 0.9932, 0.9940, 0.9929,\n",
            "        0.9911])\n",
            "0.9829050302505493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "52sexSQrjJ6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "NZUVf3zjjJ6U",
        "colab_type": "code",
        "colab": {},
        "outputId": "da29310e-d0a8-4398-e4b6-c44c1a152149"
      },
      "source": [
        "print(net)\n",
        "psize = []\n",
        "params = 0\n",
        "flops = 0\n",
        "wh = [28, 10, 1, 1, 1]\n",
        "\n",
        "#for param in list(net.parameters()):\n",
        "#    psize.append(list(param.shape))\n",
        "\n",
        "#for i in range(len(psize)//2):\n",
        "#    weight = torch.prod(torch.tensor(psize[2*i])).item()\n",
        "#    bias = psize[2*i+1][0]\n",
        "#    flop = 2*weight*wh[i]**2\n",
        "#    print(psize[2*i], psize[2*i+1], weight,\"+\",bias, ',', flop)\n",
        "#    params += weight+bias\n",
        "#    flops += flop\n",
        "\n",
        "#print(params, ',', flops)\n",
        "#print('FP performance: %3.2f Gflops' %\n",
        "#      (flops*(2*len(trainset)+len(testset))*epochs/1000000000/tt))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): LambdaLayer()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): LambdaLayer()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (2): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "i57pPX5hjJ6Y",
        "colab_type": "code",
        "colab": {},
        "outputId": "e0f35ce9-a4e0-4a7c-851e-81bf6c3914be"
      },
      "source": [
        "import numpy as np\n",
        "net_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
        "params = sum([np.prod(p.size()) for p in net_parameters])\n",
        "print(params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4286026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "9D23Zw0-jJ6a",
        "colab_type": "code",
        "colab": {},
        "outputId": "33df7b3d-9681-4cc1-d998-878060843eac"
      },
      "source": [
        "out = torch.zeros(2,4)\n",
        "torch.tensor(out.size())[1].item()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eH_Jg0kOjJ6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}